{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from PIL import Image, ImageDraw\n",
    "import glob \n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '/home/tingwei/signboard/test/train' ## The path of train data\n",
    "darknet_path = '/home/tingwei/signboard/darknet' ## The root path of YoloV4(darkenet)\n",
    "\n",
    "test_path = '/home/tingwei/signboard/private/img_private' ## The path of test data\n",
    "test_csv_path = '/home/tingwei/signboard/private/Task2_Private_String_Coordinate.csv' ## The path of test csv\n",
    "\n",
    "model_path = '/home/tingwei/signboard/team_sixyeartaipeiman/best.pth' # The path of trained model weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_path = os.path.join(train_path, 'merge_training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(os.path.join(merge_path, 'merge_training_all_handwrite.csv'))\n",
    "val_df = pd.read_csv(os.path.join(merge_path, 'merge_validation_all_handwrite.csv'))\n",
    "\n",
    "all_data_list = list(train_df['0']) + list(val_df['0'])\n",
    "all_label_list = list(train_df['1']) + list(val_df['1'])\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "all_label_list_encoded = labelencoder.fit_transform(all_label_list)\n",
    "\n",
    "label_dict = {}\n",
    "for i in range(len(all_label_list_encoded)):\n",
    "    label_dict[all_label_list[i]] = all_label_list_encoded[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b7\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "model = EfficientNet.from_pretrained('efficientnet-b7', num_classes=max(all_label_list_encoded) + 1)\n",
    "\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from natsort import natsorted as natsort\n",
    "import random\n",
    "import math\n",
    "import cv2\n",
    "from torch.backends import cudnn\n",
    "# cudnn.benchmark = True # fast training\n",
    "from torch.cuda.amp import autocast as autocast\n",
    "\n",
    "plt.ion()   # interactive mode\n",
    "\n",
    "from scipy.io import loadmat\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class DatasetLoader(Dataset):\n",
    "    def __init__(self, input_, transform, tag, label_dict):\n",
    "        self.transform = transform\n",
    "        self.tag = tag\n",
    "        self.input_ = input_\n",
    "\n",
    "\n",
    "        self.classes = list(label_dict.keys())\n",
    "        self.class_to_idx = label_dict        \n",
    "\n",
    "        images_names = self.input_\n",
    "        self.imgs = [img for i, img in enumerate(images_names)]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = self.imgs[index]\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "        if self.transform is not None:\n",
    "            img = Image.fromarray(img).convert('RGB')\n",
    "            img = self.transform(img)\n",
    "        return img\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "all_label = []\n",
    "all_points = []\n",
    "all_names = []\n",
    "all_width = []\n",
    "all_height = []\n",
    "# 開啟 JSON 檔案\n",
    "with open(os.path.join(darknet_path, 'result.json')) as f:\n",
    "    # 讀取 JSON 檔案\n",
    "    p = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9df12218bb1f44efaed5f40284d94fc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tingwei/PycharmProjects/General/venv/lib/python3.6/site-packages/ipykernel_launcher.py:76: RuntimeWarning: invalid value encountered in ulong_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "\n",
    "df_test = pd.read_csv(test_csv_path, header = None)\n",
    "test_name_list = list(df_test[0])\n",
    "save_test_path = os.path.split(test_path)[0]\n",
    "\n",
    "\n",
    "for i in tqdm(range(len(p))):\n",
    "    name = p[i]['filename']\n",
    "    public_save_index = 0\n",
    "    for public_i in range(len(test_name_list)):\n",
    "        if test_name_list[public_i] == os.path.split(name)[-1].split('.')[0]:\n",
    "            row = list(df_test.iloc[public_i])\n",
    "            \n",
    "            predict_list = []\n",
    "            tmp_img = cv2.imread(os.path.join(test_path, str(row[0]) + '.jpg'))\n",
    "            h, w, _ = tmp_img.shape\n",
    "\n",
    "            mask = Image.new('L', [w, h], 0)\n",
    "\n",
    "            crop_position = []\n",
    "            tmp_list = []\n",
    "            for k, position in enumerate(row):\n",
    "                if k == 0:\n",
    "                    continue\n",
    "                elif k % 2 == 1:\n",
    "                    if int(position) > w:\n",
    "                        position = w\n",
    "                    elif int(position) <= 0:\n",
    "                        position = 1\n",
    "                elif k % 2 == 0:\n",
    "                    if int(position) > h:\n",
    "                        position = w\n",
    "                    elif int(position) <= 0:\n",
    "                        position = 1\n",
    "                    \n",
    "                tmp_list.append(int(position))\n",
    "                if k % 2 == 0:\n",
    "                    crop_position.append(tuple(tmp_list))\n",
    "                    tmp_list = []\n",
    "\n",
    "            draw = ImageDraw.Draw(mask, 'L')\n",
    "            draw.polygon(crop_position, fill = 255)\n",
    "            \n",
    "            x_list = [x[0] for x in crop_position]\n",
    "            y_list = [x[1] for x in crop_position]\n",
    "            x_range = max(x_list) - min(x_list)\n",
    "            y_range = max(y_list) - min(y_list)\n",
    "            \n",
    "            mask = np.array(mask)\n",
    "            \n",
    "            if not os.path.exists(os.path.join(save_test_path, 'Yolo_predicted'\n",
    "                                                       , os.path.split(name)[-1].split('.')[0] + '_' + str(str(public_save_index)))):\n",
    "                        os.makedirs(os.path.join(save_test_path, 'Yolo_predicted', os.path.split(name)[-1].split('.')[0] \n",
    "                                                 + '_' + str(str(public_save_index))))\n",
    "\n",
    "            tmp_dict = {}\n",
    "            save_list = []\n",
    "            save_list.append(name)\n",
    "            tmp_j = 0\n",
    "            for j in range(len(p[i]['objects'])):\n",
    "                c_x = p[i]['objects'][j]['relative_coordinates']['center_x']\n",
    "                c_y = p[i]['objects'][j]['relative_coordinates']['center_y']\n",
    "                yolo_w = p[i]['objects'][j]['relative_coordinates']['width']\n",
    "                yolo_h = p[i]['objects'][j]['relative_coordinates']['height']\n",
    "\n",
    "                xmin = round(((2 * w * c_x) - (w * yolo_w)) / 2)\n",
    "                xmax = round(((2 * w * c_x) + (w * yolo_w)) / 2)\n",
    "                ymin = round(((2 * h * c_y) - (h * yolo_h)) / 2)\n",
    "                ymax = round(((2 * h * c_y) + (h * yolo_h)) / 2)\n",
    "                \n",
    "                bbx_mask = np.zeros([mask.shape[0], mask.shape[1]], dtype='uint8')\n",
    "                bbx_mask[ymin:ymax, xmin:xmax] = 255\n",
    "\n",
    "                if np.sum((mask//255) * (bbx_mask//255)) / np.sum(bbx_mask//255) >= 0.5:\n",
    "                    tmp_dict[tmp_j] = [xmin, ymin, xmax, ymax]\n",
    "                    tmp_j += 1\n",
    "                \n",
    "            if x_range >= y_range:\n",
    "                tmp_dict = sorted(tmp_dict.items(), key=lambda x:x[1][0]) # sort by the bounding box of xmin\n",
    "            else:\n",
    "                tmp_dict = sorted(tmp_dict.items(), key=lambda x:x[1][1]) # sort by the bounding box of ymin\n",
    "\n",
    "            for dic in range(len(tmp_dict)):\n",
    "                for dic_ele in tmp_dict[dic][1]:\n",
    "                    save_list.append(str(dic_ele))\n",
    "                    \n",
    "            tmp_list = []\n",
    "                    \n",
    "            if len(save_list) != 1:\n",
    "                for j in range(len(save_list)):\n",
    "                    if j == 0:\n",
    "                        name = save_list[j]\n",
    "                        pure_name = os.path.split(name)[-1]\n",
    "                    elif j % 4 != 0:\n",
    "                        if int(save_list[j]) < 0:\n",
    "                            save_list[j] = 0\n",
    "                        tmp_list.append(int(save_list[j]))\n",
    "                    else:\n",
    "                        if int(save_list[j]) < 0:\n",
    "                            save_list[j] = 0\n",
    "                        tmp_list.append(int(save_list[j]))\n",
    "                        save_img = tmp_img[tmp_list[1]:tmp_list[3], tmp_list[0]:tmp_list[2]]\n",
    "                        tmp_list = []\n",
    "                        cv2.imwrite(os.path.join(save_test_path, 'Yolo_predicted', str(os.path.split(name)[-1].split('.')[0]) + '_' + str(public_save_index), str(j//4) + '.png'), save_img)\n",
    "            public_save_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_path = os.path.join(save_test_path, 'Yolo_predicted')\n",
    "yolo_list = natsort(os.listdir(yolo_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "358f8eff2fde4375b8d37d01f22af6b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=30001.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_output_list = []\n",
    "img_list = []\n",
    "img_count_list = []\n",
    "for img_folder in tqdm(yolo_list):\n",
    "    folder_list = natsort(os.listdir(os.path.join(yolo_path, img_folder)))\n",
    "    if len(folder_list) == 0:\n",
    "        output_chinese = '###'\n",
    "        all_output_list.append(output_chinese)\n",
    "    else:\n",
    "        for predict_i, img_name in enumerate(folder_list):\n",
    "            img = cv2.imread(os.path.join(yolo_path, img_folder, img_name))\n",
    "            img_list.append(img)\n",
    "    img_count_list.append(len(folder_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_on_gpu = True\n",
    "data_transforms = {\n",
    "                  'test':transforms.Compose([\n",
    "#                       transforms.Resize((128, 128), interpolation=torchvision.transforms.InterpolationMode.NEAREST),\n",
    "                      transforms.Resize((256, 256)),\n",
    "#                       transforms.RandomCrop(256),\n",
    "#                       transforms.CenterCrop((256, 256)),\n",
    "#                       transforms.Grayscale(num_output_channels=1),\n",
    "                      transforms.ToTensor(),\n",
    "#                       transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                      ])\n",
    "                  }\n",
    "\n",
    "image_datasets = {'test':DatasetLoader(img_list, data_transforms['test'], 'test', label_dict)\n",
    "                 }\n",
    "\n",
    "test_batch_size = 32\n",
    "All_loader = {'test':DataLoader(dataset=image_datasets['test'], batch_size=test_batch_size, shuffle=False, num_workers=4, pin_memory=True),\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f299459707746a29558b53a27bb4c88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1770.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_output_list = []\n",
    "train_on_gpu = True\n",
    "if train_on_gpu:\n",
    "    model = model.cuda()\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for data in tqdm(All_loader['test']):\n",
    "        if train_on_gpu:\n",
    "            data = data.cuda()\n",
    "\n",
    "        output = model(data)\n",
    "\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        all_output_list += list(predicted.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key (dict_, value):\n",
    "    return [k for k, v in dict_.items() if v == value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab1ac2cda54a4a2aa57c15943922cb82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=30001.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_chinese_output = []\n",
    "now_index = 0\n",
    "for i in tqdm(img_count_list):\n",
    "    if i == 0:\n",
    "        output_chinese = '###'\n",
    "    else:\n",
    "        tmp_output = (all_output_list[now_index:now_index + i])\n",
    "        for j, label in enumerate(tmp_output):\n",
    "            if j == 0:\n",
    "                output_chinese = get_key(label_dict, label)[0]\n",
    "            else:\n",
    "                output_chinese += get_key(label_dict, label)[0]\n",
    "        now_index += i\n",
    "#     print(output_chinese)\n",
    "    all_chinese_output.append(output_chinese) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = pd.read_csv(test_csv_path, header = None)\n",
    "all_output_df = pd.concat([output_df, pd.Series(all_chinese_output).rename(9)], axis=1) # 增加列t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_output_df.to_csv(os.path.join(os.path.split(model_path)[0], 'output.csv'), header = None, index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "General",
   "language": "python",
   "name": "general"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
